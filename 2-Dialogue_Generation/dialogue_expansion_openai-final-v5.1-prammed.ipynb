{
 "cells": [
  {
   "cell_type": "raw",
   "id": "89ab8e16-91eb-47d3-bba6-2fa5f8398171",
   "metadata": {},
   "source": [
    "# msd4: 30.07.24: etwas verbessertes prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b55c4-6957-4e5e-848f-e6f75a267892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETTING UP OPENAI\n",
    "# Import necessary libraries and modules\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "from enum import Enum\n",
    "import openai\n",
    "\n",
    "# Load environment variables from a specified .env file for secure API key storage\n",
    "env_path = '/home/msd4/aidocsMosi/openAI_Token.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Retrieve the OpenAI API key from the environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    # Raise an error if the API key is not found, to prevent API calls without authentication\n",
    "    raise ValueError(\"No API key found. Please set your OPENAI_API_KEY in the .env file.\")\n",
    "\n",
    "# Initialize the OpenAI client with the retrieved API key\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Define supported OpenAI models and their token limits as an Enum for better code readability and maintainability\n",
    "# For model selection and token lengths see: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo\n",
    "class OpenAIModels(Enum):\n",
    "    GPT3_TURBO = \"gpt-3.5-turbo\"\n",
    "    GPT3_TURBO_UPDATED = \"gpt-3.5-turbo-0125\" \n",
    "    GPT4 = \"gpt-4\"\n",
    "    GPT4_TURBO = \"gpt-4-0125-preview\"\n",
    "\n",
    "# Map models to their ca. 1/3 or smaller than the respective token limits\n",
    "MODEL_TOKEN_LIMITS = {\n",
    "    OpenAIModels.GPT3_TURBO: 8000,\n",
    "    OpenAIModels.GPT3_TURBO_UPDATED: 3000,\n",
    "    OpenAIModels.GPT4: 3000,\n",
    "    OpenAIModels.GPT4_TURBO: 8000,  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153db77e-0aa2-4766-96d1-62009ee925d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dialogue(input):\n",
    "    input_dialogue = input #input is the dialogue to be expanded\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "    # CREATE GERMAN OUTLINES FROM ENGLISH INPUT-DIALOGUES INTO outline abschnitte = []\n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    outline_abschnitte = [] #Global list to store outlines of each 'Abschnitt'\n",
    "\n",
    "    '''\n",
    "    def split_query_into_parts(query: str, limit: int) -> list[str]:\n",
    "        \"\"\"Split a large text query into manageable parts according to the token limit.\"\"\"\n",
    "        return concatenate_sentences(split_into_sentences(query), limit)\n",
    "\n",
    "\n",
    "    def split_into_sentences(text: str) -> list[str]:\n",
    "        pattern = r\"(?<=[.!?])\\s+\"\n",
    "        return re.split(pattern, text)\n",
    "\n",
    "\n",
    "    def concatenate_sentences(sentences: list[str], limit: int) -> list[str]:\n",
    "        concatenated, temp, total_length = [], [], 0\n",
    "        for sentence in sentences:\n",
    "            temp.append(sentence)\n",
    "            total_length += len(sentence) + 1  # Accounting for space between sentences\n",
    "            if total_length >= limit:\n",
    "                concatenated.append(\" \".join(temp))\n",
    "                temp, total_length = [], 0\n",
    "        # Add any remaining sentences as the last chunk\n",
    "        if temp:\n",
    "            concatenated.append(\" \".join(temp))\n",
    "        return concatenated\n",
    "    '''   \n",
    "\n",
    "    def send_request(query: str, model: OpenAIModels) -> str:\n",
    "        print(\"Jetzt läuft erster %def send_request%: der englischer input_dialogue nimmt und summarized und den abschnitt zuweist\")\n",
    "        summarize_instruction = f\"\"\"Deine Aufgabe ist es einen Gesprächsverlauf während eines Rettungsdiensteinsatzes \n",
    "        bis zur Anmeldung in die Klinik auf Deutsch zu beschreiben: \n",
    "        Input-Dialog: {query}\n",
    "        Achte dabei, dass du den Gesprächsverlauf zusammmefassend wiedergibts und nach Inhalten und Themen in Abschnitten aufteilst, \n",
    "        indem du alle medizinischen Inhalte oder durchgeführte Massnahmen mitteinschliesst, \n",
    "        wie sie in Deutschen oder Schweizerischen etablierten Rettungswesen gängig sind. \n",
    "        Versuche dabei zu erkennen ob die Inhalte des Input-Dialog in welche der folgenden  Kapiteln zuzuteilen, bei denen der Inhalt passt: \n",
    "        1. Administrative Metadaten & Einsatzstellenorganisation:\n",
    "         - Adresse(n), Namen, Beteiligte, Hinweise, Gefährdungspotential(e), Lage, Beteiligte involvierte Patienten/Personen, \n",
    "         - Topografie, \n",
    "         - Unfallmechanismen\n",
    "         - Patientenpositionen\n",
    "         - Zugang zur Unfall- oder Notfallstelle\n",
    "         - Namen der involvierten medizinischen Fachpersonen, (falls keine realisitische Namen vorhanden erfinde hier welche).\n",
    "        3. ABCDE Scheme Screening o. Vorstellung Team vs. Patient:\n",
    "         - A Atemweg; B Beatmung;  C Kreislauf; D Defizit, neurologisches; E - Exposure/Environment (Exploration)\n",
    "        4. Anamneserhebung:\n",
    "         - Patientengespräch oder durch Angehörige oder externe Personen\n",
    "        5. Anschluss Geräte & Untersuchung des Patienten / Diagnostik (Vom Kopf zu den Füssen):\n",
    "         - Sauerstoffinsufflaton\n",
    "         - SpO2\n",
    "         - EKG\n",
    "         - Blutdruck\n",
    "         - Überwachung des Patienten\n",
    "         - Blutungen\n",
    "         - Verletzungen\n",
    "         - Prellmarken\n",
    "         - Hautzustand\n",
    "         - Beweglichkeiten\n",
    "         - Hörbares\n",
    "         - Riechbares\n",
    "         - Druckdolenzen\n",
    "         - Haltungen\n",
    "         - Scores erheben (GCS)\n",
    "         - Sensorik beurteilen\n",
    "         - Arbeitsdiagnose gewinnen\n",
    "         - Überwachung des Patienten\n",
    "        7. Massnahmenplanung:\n",
    "         - Lagerungsmassnahmen\n",
    "         - Beatmung\n",
    "         - Herzdruckmassage\n",
    "         - Gefässzugang pripher\n",
    "         - Gefässzugang zentral\n",
    "         - Intraossärer Zugang\n",
    "         - Flüssigkeitstherapie\n",
    "         - Medikamentöse Therapie\n",
    "         - Narkoseeinleitung\n",
    "         - Atemwegszugang\n",
    "         - Thoraxpunktion\n",
    "         - Blutungsstillung\n",
    "         - HWS-Immobilisation\n",
    "         - Wirbelsäulen- Immobilisation\n",
    "         - Repositionen\n",
    "         - Extremitäten- Immobilisierungen\n",
    "         - Überwachung des Patienten\n",
    "        8. Massnahmendurchführung & Massnahmen- Ergebniskontrolle\n",
    "         - Lagerungsmassnahmen\n",
    "         - Beatmung\n",
    "         - Herzdruckmassage\n",
    "         - Gefässzugang pripher/zentral\n",
    "         - Intraossärer Zugang\n",
    "         - Flüssigkeitstherapie\n",
    "         - Medikamentöse Therapie\n",
    "         - Narkoseeinleitung\n",
    "         - Atemwegszugang\n",
    "         - Thoraxpunktion\n",
    "         - Blutungsstillung\n",
    "         - HWS-Immobilisation\n",
    "         - Wirbelsäulen- Immobilisation\n",
    "         - Repositionen\n",
    "         - Extremitäten- Immobilisierungen\n",
    "         - Überwachung des Patienten\n",
    "         - Auswertung Sensorik\n",
    "         - Nachuntersuchungen\n",
    "        10. Entscheidung Zielklinik & Transportfähigkeit herstellen\n",
    "         - angepasst an das Krankheits- oder Verletzungsausmass\n",
    "         - Maximal-, Regel- oder Basisversorgung\n",
    "         - Psychiatrische Einrichtung\n",
    "         - Auswahl Rettungsmittel\n",
    "         - Eigenes Rettungsmittel\n",
    "         - Helikopter\n",
    "         - anderes Fahrzeug\n",
    "         - Zustand des Patienten\n",
    "         - transportfähig oder nicht transportfähig\n",
    "        12. Transport in das Rettungsmittel\n",
    "         - Transportmittel; Trage; Stuhl; Bergungstuch; Vakuummatratze; Schaufeltrage\n",
    "        13. Kontrolle im Rettungsmittel\n",
    "         - Zustand des Patienten\n",
    "         - transportfähig / nicht transportfähig\n",
    "         - Entscheidung weitere Massnahmen\n",
    "         - Überwachung des Patienten\n",
    "        14. Massnahmen im Rettungsmittel\n",
    "         - Massnahmen zur Herstellung oder Haltens der Transportfähigkeite\n",
    "         - Massnahmen, die ausserhalb des Rettungsmittels problematisch waren\n",
    "         - Narkoseeinleitung\n",
    "         - Atemweg\n",
    "         - Zugänge\n",
    "         - Überwachung des Patienten\n",
    "        15. Anmeldung Klinik im Rettungsmittel & Transport in die Klinik & Transport in die Klinik & Nachbesprechung\n",
    "         - Patientangaben gemäss Datenschutzverordnug\n",
    "         - Verletzungs- oder Erkrankungsmuster\n",
    "         - Kurzüberblick Massnahmen\n",
    "         - Zustand des Patienten\n",
    "         - ETA\n",
    "         - Entscheidung Sondersignal\n",
    "         - Überwachung des Patienten\n",
    "         - An den Zustand des Patienten angepasster Transport\n",
    "        und füge die Dialoginhalte in die passenden Schema-Abschnitte ein, \n",
    "        dort wo du keine Inhalte zuweisen kannst versuche aus dem Input-Dialog realistische Inhalte zu erfinden an dem zu dich an den Unterpunkten\n",
    "        der jeweiligen Abschnitten Orientierts.\"\n",
    "        \n",
    "        Bitte achte unbedingt darauf, dass du aus dem \"Input-Dialog\"\n",
    "        folgendes genau so exakt wiedergibts und immer in deiner Antwort integrierst: \n",
    "        -alle vorhandenen medizinischen Messwerte, Vitalwerte, Atemzüge oder Respirationen pro Minute, Schmerzskala-Werte, Schmerzbeschreibungen, Schmerzscores, numerische Schmerzangaben (pain scores),\n",
    "        - die erwähnten Interventionen, Massnahmen und Behandlungen,\n",
    "        - Medikamentennamen, Medikamentenwirkstoffe und Medikamentendosierungen, \n",
    "        - medizinische oder unfalltechnische Vorgeschichte, Diagnosen, vermutete und gestellte Diagnose, Symptome und gesundheitichen Beschwerden oder Informationen.\n",
    "        \n",
    "        Besonders bei den Medikamentennamen, Gesundheitsprobleme, medizinische Vorgeschichte und Diagnosen, musst du genau diese wiedergeben.\n",
    "        \n",
    "        Achte unbedingt darauf, dass du deine Ergebnisse pro Abschnitte immer in diesem Format ausgibts!: \n",
    "        Abschnitt Titel: <titel> \n",
    "        Geschehnisse: <geschehnisse>. \n",
    "        '\\n\\n'\n",
    "        \"\"\" \n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": summarize_instruction}], temperature=0.1,\n",
    "            model=model.value,\n",
    "        )\n",
    "        # Access the content properly based on the response object's structure\n",
    "        return response.choices[0].message.content  \n",
    "    \n",
    "    def handle_request_and_collect_summaries(input_dialogue: str, model: OpenAIModels) -> list[str]:\n",
    "        \"\"\"Process input dialogue by summarizing under thematic outlines and separate each outline to save them into a list of outlines.\"\"\"\n",
    "        token_limit = MODEL_TOKEN_LIMITS[model] \n",
    "        #parts = split_query_into_parts(input_dialogue, token_limit)\n",
    "        input_dialogue = input_dialogue\n",
    "\n",
    "        summaries = []  # Initialize an empty list to collect summaries\n",
    "\n",
    "      \n",
    "        summarized_dialogue = send_request(input_dialogue, model)\n",
    "        print(\"summarized_dialogue as a whole\")\n",
    "        print(summarized_dialogue)\n",
    "        \n",
    "        \n",
    "        abschnitte = summarized_dialogue.split('\\n\\n')  # Assuming each 'Abschnitt' is separated by two newlines\n",
    "        for abschnitt in abschnitte:\n",
    "            print(\"a single outline has been appended to the list of outlines.\")\n",
    "            if abschnitt.strip():  # Making sure it's not an empty string\n",
    "                outline_abschnitte.append(abschnitt.strip())\n",
    "            \n",
    "        print(\"\\n--- Ende der Outline herstellung: ---\\n\")\n",
    "        \n",
    "        return summaries  # Return the list of summaries for further processing\n",
    "\n",
    "\n",
    "    \"\"\"    \n",
    "        for part in parts:\n",
    "            summarized_chunk = send_request(part, model)\n",
    "            print(\"print(summarized_chunk) sollte ein  zusammengefasster chunk auf deutsch mit  Abschnitt Titel: <titel> und Geschehnisse: <geschehnisse>. sein: \")\n",
    "            print(summarized_chunk)\n",
    "            summaries.append(summarized_chunk)  # Append the summarized part to the list\n",
    "        \n",
    "            # Split the summarized part into individual 'Abschnitte' and add them to the global list\n",
    "            abschnitte = summarized_chunk.split('\\n\\n')  # Assuming each 'Abschnitt' is separated by two newlines\n",
    "            for abschnitt in abschnitte:\n",
    "                if abschnitt.strip():  # Making sure it's not an empty string\n",
    "                    outline_abschnitte.append(abschnitt.strip())\n",
    "            print(\"\\n--- Ende der Zusammenfassung des Chunks ---\\n\")\n",
    "        \n",
    "        return summaries  # Return the list of summaries for further processing\n",
    "    \"\"\"       \n",
    "        \n",
    "    def main():\n",
    "        \"\"\"Main function to execute the summarization process and capture summaries.\"\"\"\n",
    "        model = OpenAIModels.GPT4_TURBO  # Model for summarizing the input dialogue for outline-generation\n",
    "        #summaries = handle_request_and_collect_summaries(input_dialogue, model)  # Begin the summarization process and collect summaries\n",
    "        handle_request_and_collect_summaries(input_dialogue, model)  # Begin the summarization process and collect summaries\n",
    "    \n",
    "    # Execute the main function\n",
    "    main()\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "    # FROM HERE ON: EXPANDING DIALOGUES *\n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def generate_detailed_dialogue_for_abschnitt(abschnitt: str, summary_for_context: str, model, temperature: float, max_tokens: int) -> str:\n",
    "        \"\"\"Generates detailed expanded Dialogues per \"Abschnitt\".\"\"\"\n",
    "        # Extrahiere den Titel und die Ereignisse aus dem 'Abschnitt'\n",
    "        title_events_split = abschnitt.split('\\nGeschehnisse: ')\n",
    "        title_part = title_events_split[0]\n",
    "        events = title_events_split[1] if len(title_events_split) > 1 else \"\"\n",
    "        title = title_part.replace('Abschnitt Titel: ', '')\n",
    "        \n",
    "        # Konstruiere den Prompt für die Generierung des detaillierten Dialogs\n",
    "        detailed_dialogue_prompt = (\n",
    "            f\"Zusammenfassung des letzten Dialogs: {summary_for_context}\\n\\n\" \n",
    "            if summary_for_context else \"Keine Zusammenfassung vorhanden, da Beginn des Dialogs.\"\n",
    "        ) + (\n",
    "            f\"Abschnitt Titel: {title}\\n\"\n",
    "            f\"Aktuelle Geschehnisse: {events}\\n\\n\"\n",
    "    \n",
    "            f\"\"\"Entwickle einen detaillierten und realistischen Dialog, der nur die gesprochenen Worte der Personen umfasst.\n",
    "            Stelle sicher, dass die Dialoge authentisch sind und der Situation während eines Rettungsdiensteinsatzes im Deutschland\n",
    "            angemessen sind und auf den 'Aktuellen Geschehnissen' basieren.\n",
    "            Die medizinischen Fachkräfte sollen untereinander fachspezifisch kommunizieren, \n",
    "            während sie mit dem Patienten in allgemeinverständlicher medizinischer und höflicher Sprache sprechen.\n",
    "            Passe die Antworten des Patienten seinem medizinischen Zustand an, z.B. wenn er verwirrt ist \n",
    "            oder sich in einem kritischen Zustand befindet, so soll er dementsprechend kommunizieren. \n",
    "            Integriere Variabilität in die Dialoge, um die natürliche Art der Konversation widerzuspiegeln. \n",
    "            Achte unbedingt darauf dass du die unter 'Aktuelle Geschehnisse:' erwähnten Diagnosen, Symptomen, Gesundheitsbeschwerden, Medikamente, Medikamentennamen,\n",
    "            Medikamentenwirkstoffe, Dosierungen ,medizinische Maßnahmen und Messwerte genau und vollständig in die Dialoge integrierst.\n",
    "            Vermeide es, generelle Informationen zu wiederholen, die bereits erwähnt wurden, und konzentriere dich darauf, \n",
    "            den Dialog natürlich basierend auf den 'Zusammenfassung des letzten Dialogs' weiterzuführen. Achte darauf die neuen Dialoge auf die \n",
    "            medizinischen Maßnahmen anzupassen, z.B. sollen die medizinischen Fachpersonen untereinander diese klar formulieren \n",
    "            und wenn angewendet am Patienten diesen miteinbeziehen. Übernehme stets bereits erwähnten Namen.\n",
    "            Beachte folgendes:\n",
    "            Im Abschnitt: \n",
    "            \"1. Administrative Metadaten & Einsatzstellenorganisation:\" finden nur Gespräche unter dem Rettungspersonal statt die \n",
    "            einen Bezug auf die Geschehnisse unter Abschnitt: \"1. Administrative Metadaten & Einsatzstellenorganisation:\" haben.\n",
    "            Nur im im Abschnitt: \"3. ABCDE Scheme Screening & Vorstellung Team vs. Patient:\" sollen sich die medizininschen Fachpersonen \n",
    "            dem Patienten vorstellen, falls der Patient bei Bewusstsein ist.  \n",
    "            Nur im Abschnitt: \"5. Anschluss Geräte & Untersuchung des Patienten\" sollen die Fachpersonen den Patienten informieren, \n",
    "            dass er für einen IV-Zugang gestochen wird und ihm Messgeräte zur Messung der Vitalzeichen angelegt werden. \n",
    "            Halte den Dialog innerhalb des Kontexts der neuen Ereignisse und vermeide Beschreibungen sowie Satzzeichen oder Punktuation \n",
    "            und vermeide Sätze wie \"Halte durch\" oder \"Wir sind bald da\" die sich nicht auf medizinische Massnahmen beziehen \n",
    "            und vermeide Wiederholungen.\n",
    "            \n",
    "            Achte unbedingt darauf, dass du aus 'Aktuelle Geschehnisse:' folgende Informationen exakt, genau und vollständig in die Dialoge einbaust:\n",
    "            Alle medizinischen Messwerte und Resultate ohne Umrechnung, alle medizinische Informationen wie Symptome, Diagnosen, Verdachtsdiagnosen, Medikamente, Angaben zu Schmerzen wie Schmwerzscores,\n",
    "            Medikamentenwirkstoffe, Medikamentendosierungen!!!\n",
    "        \n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        print(\"*******************************************************\")\n",
    "        print(\"detailed_dialogue_prompt:  \\n\")\n",
    "        print(detailed_dialogue_prompt)\n",
    "        print(\"-------------------------------\")\n",
    "        \n",
    "        # Sende die Anfrage an die OpenAI API\n",
    "        detailed_dialogue_response = send_request(detailed_dialogue_prompt, model, temperature, max_tokens)\n",
    "        \n",
    "        print(\"detailed_dialogue_response:  \\n\")\n",
    "        print(detailed_dialogue_response)\n",
    "        print(\"*******************************************************\")\n",
    "    \n",
    "        return detailed_dialogue_response\n",
    "\n",
    "\n",
    "    def send_request(prompt: str, model: OpenAIModels, temperature: float, max_tokens: int) -> str:\n",
    "        \"\"\"Send a request to the OpenAI API with a given prompt, model, and temperature.\"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temperature,\n",
    "            model=model.value,\n",
    "            max_tokens=max_tokens  # Specify the maximum length of the output\n",
    "        )\n",
    "        # Access the content properly based on the response object's structure\n",
    "        print(\"HIER DER ZWEIZE send_request im generate dialogue response)\")\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    \n",
    "    def generate_summary(text: str, model: OpenAIModels, token_limit: int) -> str:\n",
    "        \"\"\"\n",
    "        Generate a summary for a given text. This is a simplified version.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"Mache eine Zusammenfassung was bereits gesagt wurde und was bereits geschehen ist: {text} und erwähne \n",
    "        alle Messgeräte für Vitalzeichen die angelegt wurden, die IV-Zugänge die gelegt wurden, \n",
    "        die Vitalwerte und die Namen der involvierten Personen und ob der Patient ansprechbar sein kann aufgrund seines Zustandes.\"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=model.value,\n",
    "            messages=[{\"role\": \"system\", \"content\": prompt}],\n",
    "            temperature=0.5,\n",
    "            max_tokens=token_limit\n",
    "        )\n",
    "        return response.choices[0].message.content if response.choices else \"Summary generation failed.\"\n",
    "    \n",
    "    \n",
    "    # Adjust the parameters as desired\n",
    "    temperature_setting = 0.1\n",
    "    max_output_length = 4000 \n",
    "    model = OpenAIModels.GPT4\n",
    "    \n",
    "    final_dialogue = \"\"\n",
    "    summary_for_context = \"\"\n",
    "    last_dialogue =\"\"\n",
    "\n",
    "    print(\"outline_abschnitte:____________\")\n",
    "    print(outline_abschnitte)\n",
    "    \n",
    "\n",
    "    for i, abschnitt_str in enumerate(outline_abschnitte):\n",
    "        # Splitting the string into parts based on the known labels in the string\n",
    "        parts = abschnitt_str.split(' Geschehnisse: ')\n",
    "        print(\"parts:________parts = abschnitt_str.split(' Geschehnisse: ')__________\")\n",
    "        print(parts)\n",
    "        title = parts[0].replace('Abschnitt Titel: ', '').strip()\n",
    "        events = parts[1] if len(parts) > 1 else \"\"\n",
    "    \n",
    "        if i > 0:\n",
    "            # Generate a summary of final_dialogue for context\n",
    "            summary_for_context = generate_summary(detailed_dialogue, model, max_output_length)\n",
    "    \n",
    "        # Generate detailed dialogue for the current section with context, using the modified function signature\n",
    "        detailed_dialogue = generate_detailed_dialogue_for_abschnitt(abschnitt_str, summary_for_context, model, temperature_setting, max_output_length)\n",
    "\n",
    "        # Append the generated dialogue to final_dialogue\n",
    "        final_dialogue += detailed_dialogue + \"\\n\"\n",
    "\n",
    "        \n",
    "        # Optionally print or log the intermediate results for debugging\n",
    "        print(f\"Processed section {i+1}/{len(outline_abschnitte)}\")\n",
    "        \n",
    "\n",
    "    return final_dialogue"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c95498e7-6943-4b22-a0b9-9ceab5c67757",
   "metadata": {},
   "source": [
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "\n",
    "def list_entries(collection):\n",
    "    entries = collection.find()\n",
    "    ids = []\n",
    "    for i, entry in enumerate(entries):\n",
    "        print(f\"Index: {i}, ID: {entry['_id']}\")\n",
    "        ids.append(entry['_id'])\n",
    "    return ids\n",
    "\n",
    "def get_hardcoded_ids(ids, start_index, end_index):\n",
    "    if start_index < 0 or end_index >= len(ids) or start_index > end_index:\n",
    "        print(\"Invalid range. Please enter a valid range.\")\n",
    "        return []\n",
    "    return ids[start_index:end_index + 1]\n",
    "\n",
    "def process_selected_ids(source_collection, target_collection, selected_ids):\n",
    "    for _id in selected_ids:\n",
    "        document = source_collection.find_one({\"_id\": ObjectId(_id)})\n",
    "        if document:\n",
    "            print(f\"Processing document with ID: {_id}\")\n",
    "            final_dialogue = expand_dialogue(document.get('dialogue', ''))\n",
    "            expanded_entry = {**document, 'final_dialogue': final_dialogue}\n",
    "            expanded_entry.pop('_id', None)\n",
    "            target_collection.insert_one(expanded_entry)\n",
    "        else:\n",
    "            print(f\"No document found with the ID: {_id}\")\n",
    "\n",
    "def main():\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['MIMIC-IV']\n",
    "    source_collection = db['NLP-EVAL-prammed']\n",
    "    target_collection = db['NLP-EXPANDED-prammed']\n",
    "    \n",
    "    ids = list_entries(source_collection)\n",
    "    \n",
    "    # Hardcode the start and end indexes here\n",
    "    start_index = 47 # hier immer eins weniger als in mongo\n",
    "    end_index = 59  # \n",
    "\n",
    "    \n",
    "    selected_ids = get_hardcoded_ids(ids, start_index, end_index)\n",
    "    if selected_ids:\n",
    "        process_selected_ids(source_collection, target_collection, selected_ids)\n",
    "    else:\n",
    "        print(\"No valid range selected, exiting.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a3139-e047-45f5-ba0b-4e454c355ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218d36f-0768-4a3c-b52c-89403148a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "# Assuming you have MongoDB running locally. Replace the URI with your connection details\n",
    "mongod_client = MongoClient('mongodb://localhost:27017/')\n",
    "db = mongod_client['MIMIC-IV']\n",
    "\n",
    "# Access the collection containing the dialogues\n",
    "dialogues_collection = db['NLP-EVAL-prammed']  # Source Collection\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51b01169-5c5f-4851-a37e-54dff045316a",
   "metadata": {},
   "source": [
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "\n",
    "def list_entries(collection):\n",
    "    entries = collection.find()\n",
    "    ids = []\n",
    "    for i, entry in enumerate(entries):\n",
    "        print(f\"Index: {i}, ID: {entry['_id']}\")\n",
    "        ids.append(entry['_id'])\n",
    "    return ids\n",
    "\n",
    "def list_stay_ids(collection):\n",
    "    return set(collection.distinct('stay_id'))\n",
    "\n",
    "def process_entries(source_collection, target_collection, existing_stay_ids):\n",
    "    entries = source_collection.find()\n",
    "    for entry in entries:\n",
    "        stay_id = entry['stay_id']\n",
    "        if stay_id not in existing_stay_ids:\n",
    "            print(f\"Processing document with stay_id: {stay_id}, ID: {entry['_id']}\")\n",
    "            final_dialogue = expand_dialogue(entry.get('dialogue', ''))\n",
    "            expanded_entry = {**entry, 'final_dialogue': final_dialogue}\n",
    "            expanded_entry.pop('_id', None)\n",
    "            target_collection.insert_one(expanded_entry)\n",
    "        else:\n",
    "            print(f\"Skipping document with stay_id: {stay_id}, ID: {entry['_id']} already exists in target collection\")\n",
    "\n",
    "def test_possible_new_dialogues(source_collection, target_collection):\n",
    "    existing_stay_ids = list_stay_ids(target_collection)\n",
    "    possible_new_dialogues = source_collection.count_documents({'stay_id': {'$nin': list(existing_stay_ids)}})\n",
    "    print(f\"Possible new dialogues: {possible_new_dialogues}\")\n",
    "\n",
    "    return possible_new_dialogues\n",
    "\n",
    "def main():\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['MIMIC-IV']\n",
    "    source_collection = db['NLP-EVAL-prammed']\n",
    "    target_collection = db['NLP-EXPANDED-prammed']\n",
    "    \n",
    "    # Test function to see amount of possible new dialogues\n",
    "    test_possible_new_dialogues(source_collection, target_collection)\n",
    "\n",
    "    existing_stay_ids = list_stay_ids(target_collection)\n",
    "    process_entries(source_collection, target_collection, existing_stay_ids)\n",
    "\n",
    "    print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38612075-8ba5-4d4a-b0aa-f985be67c71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "72383945-f6fc-45eb-a138-f5f8e0515f98",
   "metadata": {},
   "source": [
    "def test_function():\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['MIMIC-IV']\n",
    "    source_collection = db['NLP-EVAL-prammed']\n",
    "    target_collection = db['NLP-EXPANDED-prammed']\n",
    "    \n",
    "    # Test function to see the amount of possible new dialogues\n",
    "    test_possible_new_dialogues(source_collection, target_collection)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_function()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42a68fac-3fb7-435a-a911-0966fe5223e3",
   "metadata": {},
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea4d57-d119-4ac0-9272-e822adef3634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38edb3-af85-4fbe-805a-4c4e91cead63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb709c0-faee-40ed-b89c-359db2e6aea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b9e06cc-1523-4e0c-a29c-782117524241",
   "metadata": {},
   "source": [
    "# ---------------Process Sample from csv import---------------------------\n",
    "\n",
    "This Section was used for prompttesting after first validation of RAG turned out bad.\n",
    "\n",
    "1. Load and merge the _id values from the CSV files.\n",
    "\n",
    "2. Fetch the corresponding stay_id for these _id values from the NLP-EXPANDED-prammed collection.\n",
    "\n",
    "3. Use the stay_id to fetch the right entry from the NLP-EVAL-prammed collection.\n",
    "\n",
    "4. Process the dialogues and save the results into NLP-EXP-pram-sampled."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9becb8f2-2768-490d-897e-881c26153ad1",
   "metadata": {},
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "def load_and_merge_csv_files():\n",
    "    \"\"\"Load and merge the CSV files to get the list of IDs.\"\"\"\n",
    "    # Define the file names\n",
    "    file1 = 'common_ids_list_good-NLP-EXPANDED-prammed.csv'\n",
    "    file2 = 'common_ids_list_bad-NLP-EXPANDED-prammed.csv'\n",
    "    \n",
    "    # Load CSV files into pandas dataframes\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    \n",
    "    # Merge the dataframes\n",
    "    merged_df = pd.concat([df1, df2])\n",
    "    \n",
    "    # Extract the list of _id values\n",
    "    ids = merged_df['_id'].tolist()\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def fetch_stay_id_from_expanded(expanded_collection, document_ids):\n",
    "    \"\"\"Fetch the stay_id corresponding to given document_ids from expanded collection.\"\"\"\n",
    "    stay_ids = []\n",
    "    for document_id_str in document_ids:\n",
    "        document_id = ObjectId(document_id_str)\n",
    "        entry = expanded_collection.find_one({'_id': document_id})\n",
    "        if entry:\n",
    "            stay_id = entry.get('stay_id')\n",
    "            if stay_id:\n",
    "                stay_ids.append(stay_id)\n",
    "    return stay_ids\n",
    "\n",
    "def expand_single_dialogue_by_stay_id(stay_id, source_collection, target_collection):\n",
    "    \"\"\"Expand a single entry's dialogue by giving the stay_id.\"\"\"\n",
    "    # Find the specific document by its stay_id\n",
    "    entry = source_collection.find_one({'stay_id': stay_id})\n",
    "    \n",
    "    # Check if the entry was found\n",
    "    if entry:\n",
    "        dialogue = entry.get('dialogue', '')\n",
    "        # Assuming expand_dialogue function is defined elsewhere and accessible\n",
    "        final_dialogue = expand_dialogue(dialogue)  # Generate the expanded dialogue\n",
    "        \n",
    "        # Define the new document to insert\n",
    "        expanded_entry = {\n",
    "            **entry,  # Copy existing fields from the original document\n",
    "            'final_dialogue': final_dialogue  # Set the expanded dialogue\n",
    "        }\n",
    "        \n",
    "        # Remove _id to avoid duplicate key error\n",
    "        expanded_entry.pop('_id', None)\n",
    "        \n",
    "        # Insert the expanded dialogue into the target collection\n",
    "        target_collection.insert_one(expanded_entry)\n",
    "        print(f\"Document with stay_id {stay_id} processed and inserted into NLP-EXP-pram-sampled.\")\n",
    "    else:\n",
    "        print(f\"No document found with the stay_id: {stay_id}\")\n",
    "\n",
    "def main():\n",
    "    # Load and merge CSV files to get the list of IDs\n",
    "    document_ids = load_and_merge_csv_files()\n",
    "    \n",
    "    # MongoDB client setup\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['MIMIC-IV']\n",
    "    source_collection = db['NLP-EVAL-prammed']\n",
    "    expanded_collection = db['NLP-EXPANDED-prammed']\n",
    "    target_collection = db['NLP-EXP-pram-sampled']\n",
    "    \n",
    "    # Fetch the corresponding stay_id for these document_ids\n",
    "    stay_ids = fetch_stay_id_from_expanded(expanded_collection, document_ids)\n",
    "    \n",
    "    # Process each entry by its stay_id\n",
    "    for stay_id in stay_ids:\n",
    "        expand_single_dialogue_by_stay_id(stay_id, source_collection, target_collection)\n",
    "\n",
    "    print(\"Processing completed.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0caa3f74-4a72-4147-948a-7b1b14d9e6a2",
   "metadata": {},
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d99a691-997f-4361-93ef-66e993cfa1d6",
   "metadata": {},
   "source": [
    "## Here we do sampling, test"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2ec3b321-5f78-41ab-b222-1cbc8eecc577",
   "metadata": {},
   "source": [
    "# Check import files\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load individual CSV files\n",
    "df_good = pd.read_csv('common_ids_list_good-NLP-EXPANDED-prammed.csv')\n",
    "df_bad = pd.read_csv('common_ids_list_bad-NLP-EXPANDED-prammed.csv')\n",
    "\n",
    "# Inspect the contents of each CSV file\n",
    "print(\"Contents of the good CSV file:\")\n",
    "print(df_good)\n",
    "print(\"\\nContents of the bad CSV file:\")\n",
    "print(df_bad)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98ec3ee7-80ab-4570-93a7-11e88a85f0d6",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "# Load individual CSV files\n",
    "df_good = pd.read_csv('common_ids_list_good-NLP-EXPANDED-prammed.csv')\n",
    "df_bad = pd.read_csv('common_ids_list_bad-NLP-EXPANDED-prammed.csv')\n",
    "\n",
    "# Add type column to each DataFrame\n",
    "df_good['type'] = 'good'\n",
    "df_bad['type'] = 'bad'\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "merged_df = pd.concat([df_good, df_bad])\n",
    "\n",
    "# Resolve duplicates: set type to 'good/bad' if _id appears in both good and bad\n",
    "merged_df = merged_df.groupby('_id')['type'].apply(lambda x: 'good/bad' if len(x) > 1 else x.iloc[0]).reset_index()\n",
    "\n",
    "# Extract the list of unique _id values\n",
    "unique_ids_list = merged_df['_id'].tolist()\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['MIMIC-IV']\n",
    "expanded_collection = db['NLP-EXPANDED-prammed']\n",
    "\n",
    "# Fetch stay_id and subject_id for each _id\n",
    "stay_ids = []\n",
    "subject_ids = []\n",
    "\n",
    "for doc_id in unique_ids_list:\n",
    "    document = expanded_collection.find_one({'_id': ObjectId(doc_id)})\n",
    "    if document:\n",
    "        stay_ids.append(document.get('stay_id', ''))\n",
    "        subject_ids.append(document.get('json_data_used', {}).get('ED-EdStays-unprammed', {}).get('subject_id', ''))\n",
    "    else:\n",
    "        stay_ids.append('')\n",
    "        subject_ids.append('')\n",
    "\n",
    "# Add stay_id and subject_id to the DataFrame\n",
    "merged_df['stay_id'] = stay_ids\n",
    "merged_df['subject_id'] = subject_ids\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(merged_df)\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "merged_df.to_csv('updated_mapping_dataframe.csv', index=False)\n",
    "print(\"Updated mapping dataframe saved to updated_mapping_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f860a58f-a6f4-4141-92d3-d61cf2c4f652",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "# Load individual CSV files\n",
    "df_good = pd.read_csv('common_ids_list_good-NLP-EXPANDED-prammed.csv')\n",
    "df_bad = pd.read_csv('common_ids_list_bad-NLP-EXPANDED-prammed.csv')\n",
    "\n",
    "# Add type column to each DataFrame\n",
    "df_good['type'] = 'good'\n",
    "df_bad['type'] = 'bad'\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "merged_df = pd.concat([df_good, df_bad])\n",
    "\n",
    "# Resolve duplicates: set type to 'good/bad' if _id appears in both good and bad\n",
    "merged_df = merged_df.groupby('_id')['type'].apply(lambda x: 'good/bad' if len(x) > 1 else x.iloc[0]).reset_index()\n",
    "\n",
    "# Extract the list of unique _id values\n",
    "unique_ids_list = merged_df['_id'].tolist()\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['MIMIC-IV']\n",
    "expanded_collection = db['NLP-EXPANDED-prammed']\n",
    "sampled_collection = db['NLP-EXP-pram-sampled']\n",
    "\n",
    "# Fetch stay_id and subject_id for each _id\n",
    "stay_ids = []\n",
    "subject_ids = []\n",
    "\n",
    "for doc_id in unique_ids_list:\n",
    "    document = expanded_collection.find_one({'_id': ObjectId(doc_id)})\n",
    "    if document:\n",
    "        stay_ids.append(document.get('stay_id', ''))\n",
    "        subject_ids.append(document.get('json_data_used', {}).get('ED-EdStays-unprammed', {}).get('subject_id', ''))\n",
    "    else:\n",
    "        stay_ids.append('')\n",
    "        subject_ids.append('')\n",
    "\n",
    "# Add stay_id and subject_id to the DataFrame\n",
    "merged_df['stay_id'] = stay_ids\n",
    "merged_df['subject_id'] = subject_ids\n",
    "\n",
    "# Check for missing stay_ids in NLP-EXP-pram-sampled\n",
    "missing_stay_ids = []\n",
    "\n",
    "for stay_id in stay_ids:\n",
    "    if stay_id and not sampled_collection.find_one({'stay_id': stay_id}):\n",
    "        missing_stay_ids.append(stay_id)\n",
    "\n",
    "# Print the list of missing stay_id values and their count\n",
    "print(\"Missing stay_id values:\")\n",
    "print(missing_stay_ids)\n",
    "print(\"Total missing stay_id values:\", len(missing_stay_ids))\n",
    "\n",
    "# Function to process missing entries\n",
    "def process_missing_entries(missing_stay_ids, expanded_collection, target_collection):\n",
    "    for stay_id in missing_stay_ids:\n",
    "        entry = expanded_collection.find_one({'stay_id': stay_id})\n",
    "        if entry:\n",
    "            dialogue = entry.get('dialogue', '')\n",
    "            # Assuming expand_dialogue function is defined elsewhere and accessible\n",
    "            final_dialogue = expand_dialogue(dialogue)  # Generate the expanded dialogue\n",
    "            \n",
    "            # Define the new document to insert\n",
    "            expanded_entry = {\n",
    "                **entry,  # Copy existing fields from the original document\n",
    "                'final_dialogue': final_dialogue  # Set the expanded dialogue\n",
    "            }\n",
    "            \n",
    "            # Remove _id to avoid duplicate key error\n",
    "            expanded_entry.pop('_id', None)\n",
    "            \n",
    "            # Insert the expanded dialogue into the target collection\n",
    "            target_collection.insert_one(expanded_entry)\n",
    "            print(f\"Document with stay_id {stay_id} processed and inserted into NLP-EXP-pram-sampled.\")\n",
    "\n",
    "# Process the missing entries\n",
    "process_missing_entries(missing_stay_ids, expanded_collection, sampled_collection)\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "merged_df.to_csv('updated_mapping_dataframe.csv', index=False)\n",
    "print(\"Updated mapping dataframe saved to updated_mapping_dataframe.csv\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87eba545-2cc8-4f0d-847e-3f2c3d36f33b",
   "metadata": {},
   "source": [
    "merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7530cc-ee56-48bf-b444-92f0d3741836",
   "metadata": {},
   "source": [
    "# ----------------ENDE TEST OF SAMPLES ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677ad39-f2b1-480e-af9a-1c7098b7b218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3b144-8cd8-4e97-b633-765d2ce5380b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef324179-6d1c-4bf7-bd96-5376c6afc121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eab7f0-c4e3-4c51-9de1-a8efe51641d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb832f9e-1b24-4ee7-9369-5ddad28b35f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa58a8-c2d4-42cf-8911-1ec6bf2f29be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3360d7fa-e984-4b1f-bb38-54f4bc5b2443",
   "metadata": {},
   "source": [
    "## Processing via loop through each Doc in Source Collection\n",
    "\n",
    "This is the simplest way to process. Best if target collection is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36d420-7a2f-474b-8b58-b74cd6f97701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Loop that loops trough mongodb-collection \"NLP-EVAL-prammed\" and creates an expanded dialogue for each item's \"dialogue\" and saves an expanded \"final_dialogue\" in the collection NLP-EXPANDED-prammed.\n",
    "for entry in dialogues_collection.find():\n",
    "    dialogue = entry.get('dialogue', '')\n",
    "    final_dialogue = expand_dialogue(dialogue)  # Make sure this returns a valid string, not None\n",
    "    \n",
    "    # Explicitly define the new document to insert\n",
    "    expanded_entry = {\n",
    "        **entry,  # This copies existing fields from the original document\n",
    "        'final_dialogue': final_dialogue  # Ensures final_dialogue is explicitly set\n",
    "    }\n",
    "    \n",
    "    # Remove _id to avoid duplicate key error\n",
    "    expanded_entry.pop('_id', None)\n",
    "     \n",
    "    db['NLP-EXPANDED-prammed-2'].insert_one(expanded_entry) # Target Collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7e3e5-582e-4319-9bb9-9f3ee0ff83e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1052d2-5314-40b8-93e8-11d799b49d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960e033-5590-4c5a-8664-84c6c034b4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ff737-86d3-4a28-8c1c-e4428ce84c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e2b7ca9-52c9-4d1c-9035-da3ef9cca697",
   "metadata": {},
   "source": [
    "# Other Processing Ways/Methods/Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4fe28c-dcf9-415f-85f8-f1161aec45a5",
   "metadata": {},
   "source": [
    "#### Process single dialogue by single \"_id\" Object-Id in mongo-collection"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab50b5cb-27f9-47ab-bfc7-569465127638",
   "metadata": {},
   "source": [
    "# Create an single expanded \"final_dialogue\" by known MongoDB-ObjectId from collenction in NLP-EVAL-prammed-collection.\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "def expand_single_dialogue_by_id(document_id_str):\n",
    "    \"\"\"Expand a single entry's dialogue by giving as argument the Mongo-DB ObjectId (e.g. expand_single_dialogue_by_id(\"65f04f5ad513c4bddad10f6b\")\"\"\"\n",
    "    # Convert string ID to ObjectId\n",
    "    document_id = ObjectId(document_id_str)\n",
    "    \n",
    "    # MongoDB client setup\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['MIMIC-IV']\n",
    "    source_collection = db['NLP-EVAL-prammed']\n",
    "    target_collection = db['NLP-EXPANDED-prammed']\n",
    "    \n",
    "    # Find the specific document by its unique identifier\n",
    "    entry = source_collection.find_one({'_id': document_id})\n",
    "    \n",
    "    # Check if the entry was found\n",
    "    if entry:\n",
    "        dialogue = entry.get('dialogue', '')\n",
    "        # Assuming expand_dialogue function is defined elsewhere and accessible\n",
    "        final_dialogue = expand_dialogue(dialogue)  # Generate the expanded dialogue\n",
    "        \n",
    "        # Define the new document to insert\n",
    "        expanded_entry = {\n",
    "            **entry,  # Copy existing fields from the original document\n",
    "            'final_dialogue': final_dialogue  # Set the expanded dialogue\n",
    "        }\n",
    "        \n",
    "        # Remove _id to avoid duplicate key error\n",
    "        expanded_entry.pop('_id', None)\n",
    "        \n",
    "        # Insert the expanded dialogue into the NLP-EXPANDED-prammed collection\n",
    "        target_collection.insert_one(expanded_entry)\n",
    "        print(\"Document processed and inserted into NLP-EXPANDED-prammed.\")\n",
    "    else:\n",
    "        print(f\"No document found with the identifier: {document_id_str}\")\n",
    "\n",
    "# Call:\n",
    "expand_single_dialogue_by_id(\"660eb4177283278c541bf4e6\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fde695-c40a-43c3-82a0-a317ff090570",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a35e75da-f228-49c9-b4b0-aa178155b949",
   "metadata": {},
   "source": [
    "#### Ranged processing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa247b07-bdeb-4ad1-b8da-56d9cf823748",
   "metadata": {},
   "source": [
    "### For expanding dialogues by selecting a range from the entries in Mongo-DB's collection NLP-EVAL-prammed.\n",
    "# By making a list and then manually choosing the range of id's to be processed with the expand_dialogue-function.\n",
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "\n",
    "\n",
    "def list_entries(collection):\n",
    "    entries = collection.find()\n",
    "    ids = []\n",
    "    for i, entry in enumerate(entries):\n",
    "        print(f\"Index: {i}, ID: {entry['_id']}\")\n",
    "        ids.append(entry['_id'])\n",
    "    return ids\n",
    "\n",
    "def prompt_for_ids(ids):\n",
    "    print(\"Enter the start and end indexes of the range you want to process (e.g., 0 5):\")\n",
    "    selected_range = input().split()\n",
    "    start_index = int(selected_range[0])\n",
    "    end_index = int(selected_range[1])\n",
    "    \n",
    "    if start_index < 0 or end_index >= len(ids) or start_index > end_index:\n",
    "        print(\"Invalid range. Please enter a valid range.\")\n",
    "        return []\n",
    "    return ids[start_index:end_index + 1]\n",
    "\n",
    "def process_selected_ids(source_collection, target_collection, selected_ids):\n",
    "    for _id in selected_ids:\n",
    "        document = source_collection.find_one({\"_id\": ObjectId(_id)})\n",
    "        if document:\n",
    "            print(f\"Processing document with ID: {_id}\")\n",
    "            final_dialogue = expand_dialogue(document.get('dialogue', ''))\n",
    "            expanded_entry = {**document, 'final_dialogue': final_dialogue}\n",
    "            expanded_entry.pop('_id', None)\n",
    "            target_collection.insert_one(expanded_entry)\n",
    "        else:\n",
    "            print(f\"No document found with the ID: {_id}\")\n",
    "\n",
    "def main():\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['MIMIC-IV']\n",
    "    source_collection = db['NLP-EVAL-prammed']\n",
    "    target_collection = db['NLP-EXPANDED-prammed']\n",
    "    \n",
    "    ids = list_entries(source_collection)\n",
    "    selected_ids = prompt_for_ids(ids)\n",
    "    if selected_ids:\n",
    "        process_selected_ids(source_collection, target_collection, selected_ids)\n",
    "    else:\n",
    "        print(\"No valid range selected, exiting.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2135a6b-c520-4ff5-9ccd-58be4900f709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
