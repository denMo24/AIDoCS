{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a864de-06ef-45d4-b287-b81dabe69a7a",
   "metadata": {},
   "source": [
    "# EN RAG now for inital\n",
    "This is the version that is used for initial and final_to_english.\n",
    "\n",
    "All Dialogues are in mongodb-collection: collection = db['NLP-EXPANDED-prammed-postprocessed_translation'].\n",
    "\n",
    "RAG Results are saved per dialogue as json under directory of this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a73c2ed-fd39-4252-8b56-849cdfe09e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from accelerate import Accelerator\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Initialize the accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# MongoDB connection\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['MIMIC-IV']\n",
    "# collection = db['NLP-EXPANDED-prammed']\n",
    "collection = db['NLP-EXPANDED-prammed-postprocessed_translation'] \n",
    "\n",
    "\n",
    "# Load LLM model and tokenizer\n",
    "# model_name = \"VAGOsolutions/Llama-3-SauerkrautLM-8b-Instruct\" # sauerkraut was tested for german dialogues, but didnt perform well for diagnoses (ca. 0.33)\n",
    "model_name = \"MaziyarPanahi/Llama-3-8B-Instruct-v0.8\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "text_generation_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=200, temperature=0.2, return_full_text=False, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8a225-2180-4b5d-a7d4-e481eb6d4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionaries for customizing the prompt\n",
    "q_prefix = {\n",
    "    \"chiefcomplaint\": \"all previous or persisting\",\n",
    "    \"medication_reported\": \"every single\",\n",
    "    \"medication_pyxis\": \"every single\",\n",
    "    \"diagnosis\": \"every single assessed, suspected or considered\",\n",
    "    \"bp\": \"every single\",\n",
    "    \"heartrate\": \"every single\",\n",
    "    \"o2sat_triage\": \"every single\",\n",
    "    \"resprate\": \"every single\",\n",
    "    \"temperature\": \"every single\",\n",
    "    \"pain_triage\": \"every single\",\n",
    "}\n",
    "\n",
    "q_data = {\n",
    "    \"chiefcomplaint\": \"health problems and symptoms\",\n",
    "    \"medication_reported\": \"pharmaceuticals, drugs and medications\",\n",
    "    \"medication_pyxis\": \"pharmaceuticals, drugs, medications\",\n",
    "    \"diagnosis\": \"medical conditions or diagnoses\",\n",
    "    \"bp\": \"'blood pressure' readings values\",\n",
    "    \"heartrate\": \"'heart rate' readings, pulse values\",\n",
    "    \"o2sat_triage\": \"oxygen saturation readings\",\n",
    "    \"resprate\": \"breathing rates values, like x per minute\",\n",
    "    \"temperature\": \"temperature readings\",\n",
    "    \"pain_triage\": \"pain scale\",\n",
    "}\n",
    "\n",
    "q_postfix = {\n",
    "    \"chiefcomplaint\": \"that the patient reports having or having had\",\n",
    "    \"medication_reported\": \"that the patient says he has taken or is taking\",\n",
    "    \"medication_pyxis\": \"that the patient is being given to or administered\",\n",
    "    \"diagnosis\": \"or injuries mentioned\",\n",
    "    \"bp\": \"that are in the text snippets\",\n",
    "    \"heartrate\": \"that are in the text snippets\",\n",
    "    \"o2sat_triage\": \"that are in the text snippets\",\n",
    "    \"resprate\": \"that are in the text snippets\",\n",
    "    \"temperature\": \"that are in the text snippets\",\n",
    "    \"pain_triage\": \"levels, values or intensity that someone has \",\n",
    "}\n",
    "\n",
    "q_format = {\n",
    "    \"chiefcomplaint\": \"as a list, like: nausea; ear pain; headache, alcohol intoxication\",\n",
    "    \"medication_reported\": \"as a list, like: Aspirin 1 tablet; Paracetamol; Antihistamine\",\n",
    "    \"medication_pyxis\": \"as a csv-list of only names/labels, like: Aspirin x mg; Paracetamol; antihistamine\",\n",
    "    \"diagnosis\": \"as a list of diagnoses or symptoms, like: abd pain; hematoma; cardiac arrest\",\n",
    "    \"bp\": \"as a list of numerical values, like: 169 over 90; 169/98\",\n",
    "    \"heartrate\": \"as a csv-list of numerical values, like: 90; 100; 100\",\n",
    "    \"o2sat_triage\": \"as a list of numerical values, like: 90%; 100; 100%\",\n",
    "    \"resprate\": \"as a list of numerical values, like: 10; 20; 20\",\n",
    "    \"temperature\": \"as a list of numerical values, like: 98; 100; 37\",\n",
    "    \"pain_triage\": \"as a list of numerical values. \"\n",
    "}\n",
    "\n",
    "q_format = {\n",
    "    \"chiefcomplaint\": \"as a list, like: nausea; ear pain; headache, alcohol intoxication\",\n",
    "    \"medication_reported\": \"as a list, like: Aspirin 1 tablet; Paracetamol; Antihistamine\",\n",
    "    \"medication_pyxis\": \"as a csv-list of only names/labels, like: Aspirin x mg; Paracetamol; antihistamine\",\n",
    "    \"diagnosis\": \"as a list of diagnoses or symptoms, like: abd pain; hematoma; cardiac arrest\",\n",
    "    \"bp\": \"as a list of numerical values, like: 169 over 90; 169/98\",\n",
    "    \"heartrate\": \"as a csv-list of numerical values, like: 90; 100; 100\",\n",
    "    \"o2sat_triage\": \"as a list of numerical values, like: 90%; 100; 100%\",\n",
    "    \"resprate\": \"as a list of numerical values, like: 10; 20; 20\",\n",
    "    \"temperature\": \"as a list of numerical values, like: 98; 100; 37\",\n",
    "    \"pain_triage\": \"as a list of numerical values, like: 11; 22; 0\"\n",
    "}\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Context information is below.\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge answer always concisely.\n",
    "Please extract {q_prefix} {q_data} {q_postfix} {q_format}!\n",
    "ANSWER:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c68fbb-eb09-46da-82d4-fa150129ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(document, index):\n",
    "    dialogue = document.get('dialogue', \"\")\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=160, chunk_overlap=50)\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=40, separator=\" \")\n",
    "    chunks = text_splitter.split_text(dialogue)\n",
    "\n",
    "    embedding_model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "    embedder = HuggingFaceBgeEmbeddings(model_name=embedding_model_name)\n",
    "    vector_store = FAISS.from_texts(chunks, embedder)\n",
    "\n",
    "    answers = {}\n",
    "    for key in q_data.keys():\n",
    "        question = f\"{q_prefix[key]} {q_data[key]} {q_postfix[key]} {q_format[key]}\"\n",
    "        retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 12})\n",
    "        docs = retriever.get_relevant_documents(question)\n",
    "        context_text = \" \".join([doc.page_content for doc in docs])\n",
    "        print('Context-Text from RETRIEVER--------------------')\n",
    "        print(q_data[key])\n",
    "        print()\n",
    "        print(context_text)\n",
    "        print()\n",
    "        print('--------------------Context-Text from RETRIEVER')\n",
    "\n",
    "        prompt = prompt_template.format(\n",
    "            context=context_text,\n",
    "            q_prefix=q_prefix[key],\n",
    "            q_data=q_data[key],\n",
    "            q_postfix=q_postfix[key],\n",
    "            q_format=q_format[key]\n",
    "        )\n",
    "        \n",
    "        result = text_generation_pipeline(prompt)\n",
    "        answer = result[0]['generated_text'] if isinstance(result, list) else result\n",
    "        \n",
    "        for pattern in [\n",
    "            \"ANSWER\", \"\\n\\n\\n\", \"! ! \", \"Final Answer:\", r\"\\(Note:\",\n",
    "            \"nprint\", \"python\", r\"''''\", \"Answer:\", \"(no value mentioned)\",\n",
    "            'END OF ANSWER', 'The solution is:'\n",
    "        ]:\n",
    "            answer = re.split(pattern, answer)[0].strip()\n",
    "        \n",
    "        answer = re.sub(r\"(\\S)\\s*\\1\\s*\\1\", r\"\\1\", answer)\n",
    "        print('Answer******************************************')\n",
    "        print(answer)\n",
    "        print(':******************************************Answer')\n",
    "        print()\n",
    "        answers[key] = answer\n",
    "\n",
    "    json_data_used = document.get(\"json_data_used\", {})\n",
    "    if isinstance(json_data_used, dict):\n",
    "        for subkey in json_data_used.keys():\n",
    "            if \"_id\" in json_data_used[subkey]:\n",
    "                json_data_used[subkey][\"_id\"] = str(json_data_used[subkey][\"_id\"])\n",
    "\n",
    "    output = {\n",
    "        \"_id\": str(document[\"_id\"]),\n",
    "        \"answers\": answers,\n",
    "        \"json_data_used\": json_data_used\n",
    "    }\n",
    "    output_filename = f\"r_{index}.json\"\n",
    "    with open(output_filename, 'w') as f:\n",
    "        json.dump(output, f, indent=4)\n",
    "    return output\n",
    "\n",
    "# Set the starting index for document processing\n",
    "start_index = 102  # Change this to your specific starting index\n",
    "\n",
    "# Loop through each document starting from the start_index\n",
    "try:\n",
    "    for i, document in enumerate(collection.find().skip(start_index - 1), start_index):\n",
    "        try:\n",
    "            process_document(document, i)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing document {i}: {e}\")\n",
    "finally:\n",
    "    client.close()\n",
    "\n",
    "print(f\"Processed documents starting from index {start_index}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
